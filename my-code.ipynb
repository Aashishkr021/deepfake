{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"authorship_tag":"ABX9TyOEtjyBYYwFCRalmNswlwKP","name":"","version":""},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#jai bajrangbali\n#creation of models","metadata":{"id":"VLCOBJf5U2Jq","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T07:08:37.739751Z","iopub.execute_input":"2025-01-22T07:08:37.740099Z","iopub.status.idle":"2025-01-22T07:08:37.744332Z","shell.execute_reply.started":"2025-01-22T07:08:37.740071Z","shell.execute_reply":"2025-01-22T07:08:37.743019Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"import tensorflow as tf\n\n# Check if TensorFlow is detecting the GPU\nphysical_devices = tf.config.list_physical_devices('GPU')\nprint(\"Num GPUs Available: \", len(physical_devices))\n\n# Check detailed information about the GPU\nif len(physical_devices) > 0:\n    print(tf.config.get_logical_device_configuration(physical_devices[0]))\nelse:\n    print(\"No GPU available.\")\n!nvidia-smi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T07:08:37.746005Z","iopub.execute_input":"2025-01-22T07:08:37.746401Z","iopub.status.idle":"2025-01-22T07:08:37.915169Z","shell.execute_reply.started":"2025-01-22T07:08:37.746361Z","shell.execute_reply":"2025-01-22T07:08:37.913713Z"}},"outputs":[{"name":"stdout","text":"Num GPUs Available:  0\nNo GPU available.\n/bin/bash: line 1: nvidia-smi: command not found\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import pandas as pd\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom gym import Env\nfrom gym.spaces import Discrete, Box\nimport random\nfrom collections import deque\n\nimport gc\nimport pickle\n","metadata":{"executionInfo":{"elapsed":449,"status":"ok","timestamp":1737266330747,"user":{"displayName":"Rishabh Mishra","userId":"05918650159799530726"},"user_tz":-330},"id":"CBIvqkEC6Dpj","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T07:08:37.918656Z","iopub.execute_input":"2025-01-22T07:08:37.919115Z","iopub.status.idle":"2025-01-22T07:08:37.926245Z","shell.execute_reply.started":"2025-01-22T07:08:37.919074Z","shell.execute_reply":"2025-01-22T07:08:37.924765Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# cretion of model\nq_model = Sequential([\n   Dense(128,activation='relu'),\n   Dense(512,activation='relu'),\n   Dense(512,activation='relu'),\n   Dense(1024,activation='relu'),\n   Dense(1024,activation='relu'),\n   Dense(841,activation='linear')\n])\n\nq_model_target = Sequential([\n   Dense(128,activation='relu'),\n   Dense(512,activation='relu'),\n   Dense(512,activation='relu'),\n   Dense(1024,activation='relu'),\n   Dense(1024,activation='relu'),\n   Dense(841,activation='linear')\n])\nq_model.compile(optimizer='adam',loss='mse')\nq_model_target.compile(optimizer='adam',loss='mse')\n#q_model_target.set_weights(q_model.get_weights())  # Synchronize weights","metadata":{"executionInfo":{"elapsed":434,"status":"ok","timestamp":1737266335058,"user":{"displayName":"Rishabh Mishra","userId":"05918650159799530726"},"user_tz":-330},"id":"oNWl_JYY6qjZ","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T07:08:37.928250Z","iopub.execute_input":"2025-01-22T07:08:37.928764Z","iopub.status.idle":"2025-01-22T07:08:37.976832Z","shell.execute_reply.started":"2025-01-22T07:08:37.928714Z","shell.execute_reply":"2025-01-22T07:08:37.975425Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"","metadata":{"executionInfo":{"elapsed":446,"status":"ok","timestamp":1737266338961,"user":{"displayName":"Rishabh Mishra","userId":"05918650159799530726"},"user_tz":-330},"id":"9j6sUsYyvUCl","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Matrix for room structure (29*29)=5 rooms per floor and 5 floors with 4 stairs\nmatrix = [\n  # [1,2,3,4,5,S,1,2,3,4,5,S,1,2,3,4,5,S,1,2,3,4,5,S,1,2,3,4,5]\n    [0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], #Room1\n    [1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], #Room2\n    [1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], #Room3\n    [1,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], #Room4\n    [0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], #Room5\n    [0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], #STAIR 1\n\n    [0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], #Room1\n    [0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], #Room2\n    [0,0,0,0,0,0,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], #Room3\n    [0,0,0,0,0,0,1,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], #Room4\n    [0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], #Room5\n    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0], #STAIR 2\n\n    [0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0], #Room1\n    [0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0], #Room2\n    [0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0], #Room3\n    [0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0], #Room4\n    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0], #Room5\n    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0], #STAIR 3\n\n    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0], #Room1\n    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0,0], #Room2\n    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,1,0,0,0,0,0,0], #Room3\n    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,1,0,0,0,0,0,0], #Room4\n    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0], #Room5\n    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1], #STAIR 4\n\n    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0], #Room1\n    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0], #Room2\n    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,1], #Room3\n    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,1], #Room4\n    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], #Room5\n]","metadata":{"executionInfo":{"elapsed":461,"status":"ok","timestamp":1737266340928,"user":{"displayName":"Rishabh Mishra","userId":"05918650159799530726"},"user_tz":-330},"id":"BT_va4dK1-B_","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T07:08:37.978117Z","iopub.execute_input":"2025-01-22T07:08:37.978573Z","iopub.status.idle":"2025-01-22T07:08:38.006197Z","shell.execute_reply.started":"2025-01-22T07:08:37.978531Z","shell.execute_reply":"2025-01-22T07:08:38.004915Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"class PathEnv(Env):\n    def __init__(self):\n\n        self.action_space = Discrete(841)\n        self.n=29\n\n        self.state = random.randint(0,29)\n        self.link_matrix = np.array(matrix)\n        self.exit_rooms = np.array([28,])\n\n\n\n    def step(self, action):\n        vi = action%(self.n)\n        vj = action//(self.n)\n        if(self.state in self.exit_rooms):\n            return self.state,0,True\n        if(vi!=self.state): #<-----------------------\n          return self.state,-10,False\n\n        if(self.link_matrix[vi][vj] == 1 and vj in self.exit_rooms):\n          self.state=vj\n          return vj,1,True\n        else:\n          if(self.link_matrix[vi][vj]==0):\n            return self.state,-10,False\n          else:\n            self.state = vj\n            return vj,-1,False\n\n    def render(self):\n        return self.state\n\n    def reset(self):\n        # Reset shower temperature\n        self.state = random.randint(0,29)#changed 3 to 29\n        return self.state\n","metadata":{"executionInfo":{"elapsed":475,"status":"ok","timestamp":1737266343983,"user":{"displayName":"Rishabh Mishra","userId":"05918650159799530726"},"user_tz":-330},"id":"3jsSJpt82HjV","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T07:08:38.007371Z","iopub.execute_input":"2025-01-22T07:08:38.007737Z","iopub.status.idle":"2025-01-22T07:08:38.027163Z","shell.execute_reply.started":"2025-01-22T07:08:38.007710Z","shell.execute_reply":"2025-01-22T07:08:38.026006Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"class FireEnv(Env):\n    def __init__(self):\n        self.action_space = Discrete(841)\n        self.n=29\n        self.bottleneck_for_room = [8,9,8,5,9,0,8,9,8,5,9,0,8,9,8,5,9,0,8,9,8,5,9,0,8,9,8,5,0]\n        self.observation_space = Box(low=0,high=10,shape=(29,))\n        self.link_matrix = np.array(matrix)\n        self.p_S = np.array([8,9,8,5,9,0,8,9,8,5,9,0,8,9,8,5,9,0,8,9,8,5,9,0,8,9,8,5,0])\n        self.S = self.p_S\n        self.state = random.randint(0,29)  #new line added\n        # self.S = np.random.randint(10,size=5)\n        # self.S[4]=0\n        self.exit_rooms = np.array([28,])\n        self.p_fire_in_room = np.array([0.1,0.2,2,0.5,0.1,0,0.1,0.2,2,0.5,0.1,0,0.1,0.2,2,0.5,0.1,0,0.1,0.2,2,0.5,0.1,0,0.1,0.2,2,0.5,0])\n        self.fire_in_room = np.array([1,19,200,12,1,0.1,6,21,54,12,2,0.3,1,19,189,12,6,0,1,25,241,6,2,1,1,19,200,12,0])\n        self.p_t=1\n        self.t=1\n        self.t = 0\n        self.p = 0\n\n\n\n    def step(self, action):\n        vi = action%(self.n)\n        vj = action//(self.n)\n        # print(\"vi=\",vi,\" vj=\",vj)\n\n        # self.t=self.t+1\n\n        if np.sum(self.S)==0:\n            #return self.S,0,True\n            return 28,0,True\n        # self.fire_in_room = self.fire_in_room + np.random.rand(self.n)/10\n        self.fire_in_room = self.fire_in_room + np.array([0.005,0.02,0.04,0.006,0.02,0,0.005,0.02,0.04,0.006,0.02,0,0.005,0.02,0.04,0.006,0.02,0,0.005,0.02,0.04,0.006,0.02,0,0.005,0.02,0.04,0.006,0])\n\n        if self.p >= random.random():\n          #return self.S,-1*pow((self.fire_in_room[vj]),self.t),False\n          return vj,-1*pow((self.fire_in_room[vj]),self.t),False\n        else:\n          if np.sum(self.S) == 0:\n            return 28,0,True\n          elif self.S[vi]==0:\n            return self.state,-(1.2)*(pow(np.max(self.fire_in_room),self.t)),False\n          elif (self.link_matrix[vi][vj]!=0 and vj in self.exit_rooms):\n            self.S[vi]=self.S[vi]-1\n            if(np.sum(self.S)==0):\n                return self.state,+100/(self.link_matrix[vi][vj]),True\n            return self.state,+100/(self.link_matrix[vi][vj]),False\n          elif self.link_matrix[vi][vj]==0:\n            return vi,-2*(pow(np.max(self.fire_in_room),self.t)),False\n          elif self.S[vj] == self.bottleneck_for_room[vj]:\n            return vi,-(0.5)*(pow(np.max(self.fire_in_room),self.t))*self.link_matrix[vi][vj],False\n          else:\n            self.S[vi]=self.S[vi]-1\n            self.S[vj]=self.S[vj]+1\n            return vj,-1*(pow(self.fire_in_room[vj],self.t))*self.link_matrix[vi][vj],False\n\n\n\n    def empty_state(self):\n        arr = np.zeros(self.n)\n        # k = random.randint(0,n-1)\n        # while k in self.exit_rooms:\n        #     k=random.randint(0,n-1)\n        # arr[k]=random.randint(1,self.bottleneck_for_room)\n        return arr\n\n    def render(self):\n        return self.state\n\n    def reset(self):\n        # self.S = self.p_S\n        # self.S = np.random.randint(10,size=5)\n        # self.S=self.p_S\n        #array1 = np.full(29, 5)\n\n        self.S= np.full(29, 5)\n        self.S[28]=0\n        # self.t = self.p_t\n        self.t = 1\n        # self.fire_in_room = self.p_fire_in_room\n        # self.fire_in_room = np.array([0.1,0.2,2,0.5,0])\n        self.fire_in_room = np.array([1,1.3,8,2,0.1,0,1,1.3,8,2,0.1,0,1,1.3,8,2,0.1,0,1,1.3,8,2,0.1,0,1,1.3,8,2,0])\n        # self.S[4]=0\n        return self.state","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T07:08:38.029661Z","iopub.execute_input":"2025-01-22T07:08:38.030035Z","iopub.status.idle":"2025-01-22T07:08:38.053037Z","shell.execute_reply.started":"2025-01-22T07:08:38.030005Z","shell.execute_reply":"2025-01-22T07:08:38.052012Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"Env=PathEnv()\nfire_states=np.zeros(29)\nstate=Env.reset()\nprint(type(state))\nstate=float(state)\nprint(type(state))\nstate=np.hstack((state,fire_states))\nprint(state.shape)\nstate=np.reshape(state,(1,30))\nprint(state.shape)\n#shape of state is 1,26","metadata":{"executionInfo":{"elapsed":480,"status":"ok","timestamp":1737266351135,"user":{"displayName":"Rishabh Mishra","userId":"05918650159799530726"},"user_tz":-330},"id":"mJNo5N5P2f3D","outputId":"29ebc0f3-e6e9-4878-f04a-a00577ba805c","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T07:08:38.054916Z","iopub.execute_input":"2025-01-22T07:08:38.055220Z","iopub.status.idle":"2025-01-22T07:08:38.083198Z","shell.execute_reply.started":"2025-01-22T07:08:38.055195Z","shell.execute_reply":"2025-01-22T07:08:38.081976Z"}},"outputs":[{"name":"stdout","text":"<class 'int'>\n<class 'float'>\n(30,)\n(1, 30)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"#chosing of new action in int datatype\n\ndef chose_action(state,epsilon):\n  if random.random()>=epsilon:\n    state1=np.reshape(state,(1,30))\n    modelvalues=q_model.predict(state1)\n    action=modelvalues.argmax()\n    action=int(action)\n  else:\n    action=random.randint(0,840)\n  return action","metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1737266352996,"user":{"displayName":"Rishabh Mishra","userId":"05918650159799530726"},"user_tz":-330},"id":"KexuqX4d7S8X","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T07:08:38.084449Z","iopub.execute_input":"2025-01-22T07:08:38.084886Z","iopub.status.idle":"2025-01-22T07:08:38.103130Z","shell.execute_reply.started":"2025-01-22T07:08:38.084818Z","shell.execute_reply":"2025-01-22T07:08:38.102030Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"\nprint(type(state))\nstate=state.astype(np.float32)\nprint(state.shape)\nq_model.predict(state)\ndef soft_update(main_model, target_model, tau):\n\n    print(\"it is soft update\")\n    for target_var, main_var in zip(target_model.variables, main_model.variables):\n        target_var.assign(tau * main_var + (1 - tau) * target_var)","metadata":{"executionInfo":{"elapsed":925,"status":"ok","timestamp":1737266355637,"user":{"displayName":"Rishabh Mishra","userId":"05918650159799530726"},"user_tz":-330},"id":"UvbFjW5k8y1v","outputId":"93bf425b-573e-416e-f160-d2f7850c2a48","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T07:08:38.104750Z","iopub.execute_input":"2025-01-22T07:08:38.105116Z","iopub.status.idle":"2025-01-22T07:08:38.705815Z","shell.execute_reply.started":"2025-01-22T07:08:38.105087Z","shell.execute_reply":"2025-01-22T07:08:38.704756Z"}},"outputs":[{"name":"stdout","text":"<class 'numpy.ndarray'>\n(1, 30)\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"memory = deque(maxlen=50000)\n#print(q_model_target.output_shape)\nprint(q_model.input_dtype)\ndef store_experience(memory, state, action, reward, next_state, done):\n    memory.append((state, action, reward, next_state, done))","metadata":{"executionInfo":{"elapsed":480,"status":"ok","timestamp":1737266358013,"user":{"displayName":"Rishabh Mishra","userId":"05918650159799530726"},"user_tz":-330},"id":"IJxleHOZ4UkZ","outputId":"d2c803b4-5974-4e47-c2b7-d4975713e4c5","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T07:08:38.706954Z","iopub.execute_input":"2025-01-22T07:08:38.707321Z","iopub.status.idle":"2025-01-22T07:08:38.713782Z","shell.execute_reply.started":"2025-01-22T07:08:38.707290Z","shell.execute_reply":"2025-01-22T07:08:38.712286Z"}},"outputs":[{"name":"stdout","text":"float32\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef training(memory,epsilon,gamma):\n    total_target=np.zeros((10000,841))\n    next_states=np.zeros((10000,30))\n    states=np.zeros((10000,30))\n    minibatch = random.sample(memory, 10000)\n    _, actions, rewards, next_states, dones = zip(*minibatch)\n    next_states=np.array(next_states)\n    total_target = q_model_target.predict(next_states)\n    total_target=np.squeeze(total_target,axis=1)\n    \n    print(total_target.shape)\n    \n    i=0\n    for state, action, reward, next_state, done in minibatch:\n        states[i]=state\n        if done:\n            print(epsilon)\n            total_target[i][action] = reward\n            i=i+1\n            epsilon=epsilon-0.1\n    \n        else:\n            #next_state=np.hstack(next_state,fire_states)\n            total_target[i][action] = reward + gamma * np.amax(total_target[i])\n\n            i=i+1\n            \n    print(states)            \n    q_model.fit(states, total_target, epochs=1, verbose=0)\n    soft_update(q_model, q_model_target, tau)\n","metadata":{"executionInfo":{"elapsed":434,"status":"ok","timestamp":1737263006077,"user":{"displayName":"Rishabh Mishra","userId":"05918650159799530726"},"user_tz":-330},"id":"WcRNjvZ66BgL","outputId":"5aa5ff17-6e32-44ba-a4ed-b1baead33ae3","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T07:08:38.714985Z","iopub.execute_input":"2025-01-22T07:08:38.715299Z","iopub.status.idle":"2025-01-22T07:08:38.738408Z","shell.execute_reply.started":"2025-01-22T07:08:38.715273Z","shell.execute_reply":"2025-01-22T07:08:38.737172Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"episodes=5\ngamma=0.995\ntau=0.4\nepsilon=0.1\nimport numpy as np\nstore=np.zeros(episodes)\nfor episode in range(episodes):\n  state=PathEnv.reset(self=Env)\n  state=float(state)\n  state=np.hstack((state,fire_states))\n  state=np.reshape(state,(1,30))\n  done=False\n  i=0\n  print(episode)\n  while done==False and i<=10000:\n    i=i+1\n    #print(i)\n    action=chose_action(state,epsilon)\n    next_state,reward,done=Env.step(action)\n    next_state=np.array(float(next_state))\n    next_state=np.hstack((next_state,fire_states))\n    next_state=np.reshape(next_state,(1,30))\n    store_experience(memory, state, action, reward, next_state, done)#state is array of 1,30 and next state is int32\n    state=next_state\n  print(store)  \n  store[episode]=i\n  training(memory,epsilon,gamma)1","metadata":{"id":"5Br4HvRR5LJf","trusted":true,"execution":{"execution_failed":"2025-01-22T07:43:00.766Z"}},"outputs":[],"execution_count":null},{"cell_type":"raw","source":"q_model.save(\"q_model.h5\")\nq_model.save (\"/kaggle/working/q_model1.keras\")","metadata":{}},{"cell_type":"markdown","source":"q_model.save(\"q_model.keras\")","metadata":{"id":"mX92_KND23zb"}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom collections import deque\nimport random\n\n# Set parameters for the environment\nstate_size = 10  # Example state dimension\naction_size = 4  # Example action space size\nlearning_rate = 0.001\ngamma = 0.99  # Discount factor\n\n# Initialize Q and Target models\ndef build_model(state_size, action_size, learning_rate):\n    model = tf.keras.Sequential([\n        tf.keras.layers.Dense(128, input_dim=state_size, activation='relu'),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Dense(1024, activation='relu'),\n        tf.keras.layers.Dense(1024, activation='relu'),\n        tf.keras.layers.Dense(action_size, activation='linear')\n    ])\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')\n    return model\n\nq_model = build_model(state_size, action_size, learning_rate)\nq_model_target = build_model(state_size, action_size, learning_rate)\nq_model_target.set_weights(q_model.get_weights())  # Synchronize weights\n\n# Replay memory\nmemory = deque(maxlen=2000)\n\n# Epsilon-greedy strategy\nepsilon = 1.0  # Initial exploration rate\nepsilon_min = 0.01\nepsilon_decay = 0.995\n\n# Action selection\ndef select_action(state, epsilon, q_model):\n    if np.random.rand() <= epsilon:\n        return random.randrange(action_size)  # Explore\n    q_values = q_model.predict(state)\n    return np.argmax(q_values[0])  # Exploit\n\n# Store experience\ndef store_experience(memory, state, action, reward, next_state, done):\n    memory.append((state, action, reward, next_state, done))\n\n# Train the Q-network\ndef train_q_network(q_model, q_model_target, memory, batch_size):\n    if len(memory) < batch_size:\n        return\n\n    minibatch = random.sample(memory, batch_size)\n    for state, action, reward, next_state, done in minibatch:\n        target = q_model.predict(state)\n        if done:\n            target[0][action] = reward\n        else:\n            t = q_model_target.predict(next_state)\n            target[0][action] = reward + gamma * np.amax(t[0])\n\n        q_model.fit(state, target, epochs=1, verbose=0)\n\n# Update target network\ndef update_target_network(q_model, q_model_target):\n    q_model_target.set_weights(q_model.get_weights())\n\n# Simulate custom environment\ndef custom_environment_step(state, action):\n    # Placeholder for environment logic\n    next_state = np.random.rand(state_size)  # Example state transition\n    reward = np.random.rand()  # Example reward\n    done = random.choice([True, False])  # Random termination\n    return next_state, reward, done\n\n# Training loop\nepisodes = 1000\nbatch_size = 32\n\nfor episode in range(episodes):\n    state = np.random.rand(1, state_size)  # Example initial state\n    total_reward = 0\n    done = False\n\n    while not done:\n        action = select_action(state, epsilon, q_model)\n        next_state, reward, done = custom_environment_step(state, action)\n        store_experience(memory, state, action, reward, np.reshape(next_state, [1, state_size]), done)\n        train_q_network(q_model, q_model_target, memory, batch_size)\n        state = np.reshape(next_state, [1, state_size])\n        total_reward += reward\n\n    update_target_network(q_model, q_model_target)\n\n    # Decay epsilon\n    if epsilon > epsilon_min:\n        epsilon *= epsilon_decay\n\n    print(f\"Episode {episode + 1}, Total Reward: {total_reward:.2f}, Epsilon: {epsilon:.2f}\")\n","metadata":{"executionInfo":{"elapsed":7160,"status":"error","timestamp":1737261386450,"user":{"displayName":"Rishabh Mishra","userId":"05918650159799530726"},"user_tz":-330},"id":"iOL-CHiJvqfc","outputId":"a42bdd0b-4624-42ec-9cb1-771a2268f7e8","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T07:43:58.702282Z","iopub.execute_input":"2025-01-22T07:43:58.702667Z","iopub.status.idle":"2025-01-22T07:44:18.449363Z","shell.execute_reply.started":"2025-01-22T07:43:58.702637Z","shell.execute_reply":"2025-01-22T07:44:18.447435Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Episode 1, Total Reward: 0.26, Epsilon: 0.99\nEpisode 2, Total Reward: 0.47, Epsilon: 0.99\nEpisode 3, Total Reward: 0.60, Epsilon: 0.99\nEpisode 4, Total Reward: 0.86, Epsilon: 0.98\nEpisode 5, Total Reward: 0.77, Epsilon: 0.98\nEpisode 6, Total Reward: 1.08, Epsilon: 0.97\nEpisode 7, Total Reward: 3.05, Epsilon: 0.97\nEpisode 8, Total Reward: 0.63, Epsilon: 0.96\nEpisode 9, Total Reward: 1.50, Epsilon: 0.96\nEpisode 10, Total Reward: 0.51, Epsilon: 0.95\nEpisode 11, Total Reward: 1.50, Epsilon: 0.95\nEpisode 12, Total Reward: 0.67, Epsilon: 0.94\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\nEpisode 13, Total Reward: 2.06, Epsilon: 0.94\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\nEpisode 14, Total Reward: 0.97, Epsilon: 0.93\nEpisode 15, Total Reward: 0.13, Epsilon: 0.93\nEpisode 16, Total Reward: 0.78, Epsilon: 0.92\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d86a88409512>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_environment_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mstore_experience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mtrain_q_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_model_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-d86a88409512>\u001b[0m in \u001b[0;36mtrain_q_network\u001b[0;34m(q_model, q_model_target, memory, batch_size)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Update target network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;31m# Create an iterator that yields batches for one epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         epoch_iterator = TFEpochIterator(\n\u001b[0m\u001b[1;32m    283\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, distribute_strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribute_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             dataset = self._distribute_strategy.experimental_distribute_dataset(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/array_data_adapter.py\u001b[0m in \u001b[0;36mget_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[0;34m(self, map_func, name)\u001b[0m\n\u001b[1;32m   2354\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2355\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflat_map_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2356\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mflat_map_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2357\u001b[0m     \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/flat_map_op.py\u001b[0m in \u001b[0;36m_flat_map\u001b[0;34m(input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_flat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-private-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;34m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_FlatMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/flat_map_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     variant_tensor = gen_dataset_ops.flat_map_dataset(\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mflat_map_dataset\u001b[0;34m(input_dataset, other_arguments, f, output_types, output_shapes, metadata, name)\u001b[0m\n\u001b[1;32m   2424\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2425\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2426\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   2427\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FlatMapDataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_arguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2428\u001b[0m         \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_shapes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"\"#creatin of dataset to train\nm=25#states of fire environment\nmt=10000\nn=1\nfire_states=np.zeros(m)\ndones=np.zeros(mt)\nstates=np.zeros((mt,m+n))\nrewards=np.zeros(mt)\nnext_states=np.zeros((mt,m+n))\nactions=np.zeros(mt)\ns=np.array(Env.render())\nfor i in range(mt):\n  Env.reset()\n  s=np.array(Env.render())\n\n  state=np.hstack((s,fire_states))\n  states[i]=state\n  action=chose_action(state,1)\n  s,reward,done=Env.step(action)\n  next_states[i]=np.hstack((s,fire_states))\n  rewards[i]=reward\n  actions[i]=action\n # print(state)\n  dones[i]=done\nqt_values=q_model_target.predict(next_states)\nqtmax_values=np.amax(qt_values,axis=1)\ntarget_values=rewards+qtmax_values\nq_values = q_model.predict(states)\nfor i, action in enumerate(actions):\n  q_values[i, action] = target_values[i]\nprint(qt_values.shape)\n\nq_model.fit(states,q_vales)\n","metadata":{"executionInfo":{"elapsed":779,"status":"error","timestamp":1737261785648,"user":{"displayName":"Rishabh Mishra","userId":"05918650159799530726"},"user_tz":-330},"id":"F7h1RafqE_dI","outputId":"3dd77a38-10f6-49f9-e67c-07a35956a86f","jupyter":{"source_hidden":true},"trusted":true,"execution":{"execution_failed":"2025-01-22T07:43:00.765Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"q_value=q_model.predict(states)","metadata":{"executionInfo":{"elapsed":3172,"status":"ok","timestamp":1737219096906,"user":{"displayName":"Rishabh Mishra","userId":"05918650159799530726"},"user_tz":-330},"id":"eisSO62Kpm0m","outputId":"acfcd65b-b467-47ba-9ea3-f188a069192e","jupyter":{"source_hidden":true},"trusted":true,"execution":{"execution_failed":"2025-01-22T07:43:00.765Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a=q_value.argmax(axis=1)\nprint(a.shape)\nprint(a)\nprint(rewards.shape)\nprint(states)","metadata":{"executionInfo":{"elapsed":1119,"status":"ok","timestamp":1737219177374,"user":{"displayName":"Rishabh Mishra","userId":"05918650159799530726"},"user_tz":-330},"id":"rGTyejROSD_d","outputId":"a54ef49a-d158-44c0-efec-66b829b39cee","trusted":true,"execution":{"execution_failed":"2025-01-22T07:43:00.765Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#CODE TO CHECK THE MODEL\ns=np.array(Env.render())\ndone=False\nsteps=0\nwhile done==False:\n  steps=steps+1\n\n  state=np.hstack((s,fire_states))\n  action=chose_action(state,0.8)\n  s,reward,done=Env.step(action)\n  reward_s=rewards+reward\n  print(steps,reward,s)\n #state=np.hstack((s1,fire_states))\n\n  #action=chose_action(state,epsilon)","metadata":{"executionInfo":{"elapsed":65890,"status":"error","timestamp":1737217761348,"user":{"displayName":"Rishabh Mishra","userId":"05918650159799530726"},"user_tz":-330},"id":"CZYooPji_5c0","outputId":"b0ccaff2-ff3c-4767-c130-79841e82a988","trusted":true,"execution":{"execution_failed":"2025-01-22T07:43:00.765Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"p-bXlo_GOyUU","trusted":true},"outputs":[],"execution_count":null}]}